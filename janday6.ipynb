{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhav9369755717/AI-ML-2-internship-/blob/main/janday6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVdK7rqoMVmM"
      },
      "source": [
        "# DAY 6 – Model Behavior, Overfitting, Underfitting & Feature Scaling\n",
        "\n",
        "## Objective of Day 6\n",
        "The goal of this session is to understand **why a Machine Learning model behaves the way it does** and how to **improve model performance correctly**.\n",
        "\n",
        "By the end of this class, students will be able to:\n",
        "- Explain overfitting and underfitting\n",
        "- Compare training vs test performance\n",
        "- Understand why feature scaling is required\n",
        "- Apply feature scaling correctly\n",
        "- Improve model stability using industry practices\n"
      ],
      "id": "NVdK7rqoMVmM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvTiGB6MVmN"
      },
      "source": [
        "## Context from Day 5\n",
        "\n",
        "In Day 5, we:\n",
        "- Used Train–Test Split\n",
        "- Trained a model only on training data\n",
        "- Evaluated performance on unseen test data\n",
        "\n",
        "We noticed that accuracy can change.\n",
        "Day 6 explains **why this happens** and **what to do about it**.\n"
      ],
      "id": "WIvTiGB6MVmN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lyEAYb_MVmO"
      },
      "source": [
        "## Overfitting\n",
        "\n",
        "Overfitting occurs when:\n",
        "- Training accuracy is very high\n",
        "- Test accuracy is significantly lower\n",
        "\n",
        "This means the model has memorized training data instead of learning general patterns.\n"
      ],
      "id": "1lyEAYb_MVmO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_uJH67CMVmO"
      },
      "source": [
        "## Underfitting\n",
        "\n",
        "Underfitting occurs when:\n",
        "- Training accuracy is low\n",
        "- Test accuracy is also low\n",
        "\n",
        "This means the model is too simple and has not learned enough from the data.\n"
      ],
      "id": "T_uJH67CMVmO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4h9A3fKMVmO"
      },
      "source": [
        "## Import Required Libraries\n"
      ],
      "id": "A4h9A3fKMVmO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0fBD2BIMVmO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "id": "o0fBD2BIMVmO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COw5hDqBMVmP"
      },
      "source": [
        "## Dataset (Same as Day 5)\n",
        "\n",
        "We keep the dataset unchanged to focus only on **model behavior and improvement techniques**.\n"
      ],
      "id": "COw5hDqBMVmP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke0JALgnMVmP"
      },
      "outputs": [],
      "source": [
        "X = np.array([\n",
        "    [7.5, 1, 3],\n",
        "    [6.2, 0, 2],\n",
        "    [8.1, 2, 4],\n",
        "    [7.0, 1, 3],\n",
        "    [8.5, 3, 5],\n",
        "    [5.9, 0, 1],\n",
        "    [7.8, 2, 4],\n",
        "    [6.8, 1, 2]\n",
        "])\n",
        "\n",
        "y = np.array([1, 0, 1, 1, 1, 0, 1, 0])"
      ],
      "id": "Ke0JALgnMVmP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8aj7A_5MVmP"
      },
      "source": [
        "## Train–Test Split\n",
        "\n",
        "We split the data to evaluate how well the model generalizes to unseen data.\n"
      ],
      "id": "G8aj7A_5MVmP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHlCFwe-MVmQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")"
      ],
      "id": "RHlCFwe-MVmQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU6bwyqRMVmQ"
      },
      "source": [
        "## Training the Model Without Feature Scaling\n",
        "\n",
        "First, we train the model using raw feature values.\n",
        "This helps us observe baseline behavior.\n"
      ],
      "id": "VU6bwyqRMVmQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od3USwS1MVmQ",
        "outputId": "62d64514-ca13-4615-a0bd-020ed06a4d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (No Scaling): 0.8333333333333334\n",
            "Test Accuracy (No Scaling): 1.0\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "\n",
        "print(\"Training Accuracy (No Scaling):\", train_accuracy)\n",
        "print(\"Test Accuracy (No Scaling):\", test_accuracy)"
      ],
      "id": "Od3USwS1MVmQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH6gius5MVmQ"
      },
      "source": [
        "## Why Feature Scaling is Required\n",
        "\n",
        "Different features have different ranges:\n",
        "- CGPA: 0–10\n",
        "- Internships: 0–3\n",
        "- Coding skill: 1–5\n",
        "\n",
        "Models like Logistic Regression are sensitive to feature scales.\n",
        "Without scaling, features with larger ranges can dominate learning.\n"
      ],
      "id": "oH6gius5MVmQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya5455k7MVmQ"
      },
      "source": [
        "## Feature Scaling Using StandardScaler\n",
        "\n",
        "StandardScaler transforms features so that:\n",
        "- Mean becomes 0\n",
        "- Standard deviation becomes 1\n",
        "\n",
        "Scaling is fitted on training data only to avoid data leakage.\n"
      ],
      "id": "ya5455k7MVmQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8JadLOVMVmQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "id": "W8JadLOVMVmQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uFoyiPfMVmQ"
      },
      "source": [
        "## Training the Model After Feature Scaling\n",
        "\n",
        "We retrain the same model using scaled features.\n"
      ],
      "id": "3uFoyiPfMVmQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jys_NNmVMVmQ",
        "outputId": "a0f6e9fb-fa8a-4849-eacc-098ecf765c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (Scaled): 0.8333333333333334\n",
            "Test Accuracy (Scaled): 1.0\n"
          ]
        }
      ],
      "source": [
        "scaled_model = LogisticRegression()\n",
        "scaled_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "scaled_train_accuracy = scaled_model.score(X_train_scaled, y_train)\n",
        "scaled_test_accuracy = scaled_model.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Training Accuracy (Scaled):\", scaled_train_accuracy)\n",
        "print(\"Test Accuracy (Scaled):\", scaled_test_accuracy)"
      ],
      "id": "Jys_NNmVMVmQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn2ScOMsMVmR"
      },
      "source": [
        "## Key Observations\n",
        "\n",
        "- Training and test accuracy can differ due to overfitting or underfitting\n",
        "- Feature scaling often improves stability and fairness among features\n",
        "- Test accuracy is the primary metric for judging real-world performance\n",
        "- Model improvement is an iterative process\n"
      ],
      "id": "zn2ScOMsMVmR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymSPCnYtMVmR"
      },
      "source": [
        "## Industry Perspective\n",
        "\n",
        "In real-world projects:\n",
        "- Models are evaluated repeatedly\n",
        "- Features are scaled and engineered\n",
        "- Performance is monitored and improved over time\n",
        "\n",
        "Day 6 introduces this professional mindset.\n"
      ],
      "id": "ymSPCnYtMVmR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWMKdZp2MVmR"
      },
      "source": [
        "## What Comes Next\n",
        "\n",
        "Next, we will:\n",
        "- Compare multiple ML models\n",
        "- Understand model selection\n",
        "- Use additional evaluation metrics\n",
        "- Make the project interview-ready\n"
      ],
      "id": "WWMKdZp2MVmR"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}